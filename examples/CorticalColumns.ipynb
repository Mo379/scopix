{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87932a25-eb74-443c-a1c0-c6728c21fafc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/aion/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<contextlib._GeneratorContextManager at 0x105f046d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "from _src.dataset.cifar10 import load_cifar10\n",
    "from _src.logger.WANDB import WANDBLogger\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "jax.disable_jit(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773038f1-d90f-4ee0-8475-da9c70bb920b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 40000, Eval size: 10000, Test size: 10000\n",
      "Batch images shape: torch.Size([32, 32, 32, 3]), Batch labels shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = load_cifar10(batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "234874b2-f9c7-4e85-8e48-3efa3b6d7831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 32, 32, 3]), torch.Size([32]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b0ff8-100b-42fa-8900-8db55480db3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_samples(loader, class_names=None, n=8):\n",
    "    \"\"\"Show n samples from a PyTorch DataLoader.\"\"\"\n",
    "    images, labels = next(iter(loader))\n",
    "    images = images[:n]\n",
    "    labels = labels[:n]\n",
    "\n",
    "    plt.figure(figsize=(12, 2))\n",
    "    for i in range(n):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        img = images[i]\n",
    "        plt.imshow(img)\n",
    "        if class_names is not None:\n",
    "            plt.title(class_names[labels[i]])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# CIFAR-10 class names:\n",
    "class_names = [\n",
    "    'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "    'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "]\n",
    "\n",
    "# Show a few samples from each split\n",
    "show_samples(train_loader, class_names, n=8)\n",
    "show_samples(val_loader, class_names, n=8)\n",
    "show_samples(test_loader, class_names, n=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb33915-bebe-438e-89ca-85d327431a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_positions(input_shape, patch_shape):\n",
    "    H, W, C = input_shape\n",
    "    ph, pw, _ = patch_shape\n",
    "\n",
    "    nh, nw = H // ph, W // pw\n",
    "\n",
    "    # patch centers\n",
    "    y = (jnp.arange(nh) * ph + ph/2) - H/2\n",
    "    x = (jnp.arange(nw) * pw + pw/2) - W/2\n",
    "\n",
    "    # normalize to [-1, 1]\n",
    "    y = (y / (H/2)).astype(jnp.float32)\n",
    "    x = (x / (W/2)).astype(jnp.float32)\n",
    "\n",
    "    grid_y, grid_x = jnp.meshgrid(y, x, indexing=\"ij\")\n",
    "    positions = jnp.stack([grid_y, grid_x], axis=-1).reshape(-1, 2)\n",
    "\n",
    "    return positions  # shape (num_patches, 2), dtype float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d447209-f01e-49e8-9ec7-6f41045bc599",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " The Inference of a cortical column\n",
    "(torch.Size([32, 32, 32, 3]), torch.Size([32]))\n",
    "Args:\n",
    "    sensory_input:\n",
    "    location_input:\n",
    "    action_efference:\n",
    "Layers:\n",
    "    Layer 4: The what signal, Recieves sensory input \n",
    "        takes -> Sensory Input\n",
    "    \n",
    "    Layer 5: Recieves an action efference copy and passes it to layer 6\n",
    "    Layer 6: The where signal, Grid cell like encoding position of the sensor\n",
    "        Inputs -> Location Input, action efference (from layer 5)\n",
    "        This layer performs path integration using the input\n",
    "\n",
    "    Layer 1: Biological Wiring (Can be ignored) [Assumption made, I could be catastophically wrong ;)]\n",
    "    Layer 2/3: Place Neurons: This is the binding layer combining what and where infor\n",
    "        Inputs -> Sensory Input from L4, and the location context from L6\n",
    "    \n",
    "returns:\n",
    "    sensory_location_latent:\n",
    "    location_update:\n",
    "Concerns:\n",
    "    - How many neurons in each column\n",
    "    - Should any part of this be learnable or should it just be an algorithm ? (it's OK if learnable)\n",
    "\"\"\" \n",
    "class CorticalColumn(hk.Module):\n",
    "    NetName = 'CorticalColumn'\n",
    "    # The core idea is learning the structure of things through sensory motor coupling\n",
    "    # Every column has its own sensory-motor loop/system - Thousand Brains Theory\n",
    "    # Reference frame, path integration\n",
    "    # Columns gain predictive power after a large enough refrence frame is built\n",
    "    # Brain Region -> Sensory Input, Motor Output\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_hidden,\n",
    "            hidden_size,\n",
    "            output_size,\n",
    "            enable_inhibition=False,\n",
    "            name='CorticalColumn'\n",
    "    ):\n",
    "        super().__init__(name=name)\n",
    "        self.n_hidden = n_hidden\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.enable_inhibition = enable_inhibition\n",
    "\n",
    "    def __call__(self, sensory_input, location_input):\n",
    "        sensory_emb = hk.Linear(self.hidden_size)(sensory_input.reshape(-1))\n",
    "        location_emb = hk.Linear(self.hidden_size)(location_input)\n",
    "        \n",
    "        # Combine with nonlinear mixing instead of trivial addition\n",
    "        sensory_location_emb = jax.nn.relu(\n",
    "            hk.Linear(self.hidden_size)(jnp.concatenate([sensory_emb, location_emb], axis=-1))\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Residual MLP for binding \"what\" and \"where\"\n",
    "        x = sensory_location_emb\n",
    "        for _ in range(self.n_hidden):\n",
    "            residual = x\n",
    "            x = hk.Linear(self.hidden_size)(x)\n",
    "            x = jax.nn.relu(x)\n",
    "            x = residual + x\n",
    "        \n",
    "        # Final projections\n",
    "        sensory_location_latent = hk.Linear(self.output_size)(x)\n",
    "        return sensory_location_latent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16fb21c-e147-4365-922a-0da066656940",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualCortex(hk.Module):\n",
    "    NetName = 'VisiualCortex'\n",
    "    # The core idea is learning the structure of things through sensory motor coupling\n",
    "    # Every column has its own sensory-motor loop/system - Thousand Brains Theory\n",
    "    # Reference frame, path integration\n",
    "    # Columns gain predictive power after a large enough refrence frame is built\n",
    "    # Brain Region -> Sensory Input, Motor Output\n",
    "    def __init__(\n",
    "            self,\n",
    "            #cortical\n",
    "            cortical_side_size,\n",
    "            cortical_n_hidden,\n",
    "            cortical_hidden_size,\n",
    "            cortical_output_size,\n",
    "            name='VisiualCortex'\n",
    "            ):\n",
    "        super().__init__(name=name)\n",
    "        # Cortical Config\n",
    "        self.cortical_side_size = cortical_side_size\n",
    "        self.cortical_n_hidden = cortical_n_hidden\n",
    "        self.cortical_hidden_size = cortical_hidden_size\n",
    "        self.cortical_output_size = cortical_output_size\n",
    "    def cortical_observation(\n",
    "        self,\n",
    "        cortical_input,\n",
    "        side_size,\n",
    "        n_hidden,\n",
    "        hidden_size,\n",
    "        output_size\n",
    "    ):\n",
    "        H, W, C = cortical_input.shape\n",
    "        assert side_size // H == 0 and side_size < H, 'Cortical Side must perfectly fit'\n",
    "        sensory_input = jnp.reshape(\n",
    "            cortical_input,\n",
    "            (-1, side_size, side_size, C)\n",
    "        )\n",
    "        location_input = patch_positions(\n",
    "            input_shape=cortical_input.shape,\n",
    "            patch_shape=(side_size, side_size, C)\n",
    "        )\n",
    "        #\n",
    "        cortical_sheet_net = jax.vmap(CorticalColumn(\n",
    "            n_hidden=n_hidden,\n",
    "            hidden_size=hidden_size,\n",
    "            output_size=output_size,\n",
    "            enable_inhibition=True,\n",
    "            name=f'CorticalColumn_{side_size}'\n",
    "        ), in_axes=0)\n",
    "        #\n",
    "        sensory_location = cortical_sheet_net(\n",
    "            sensory_input, location_input\n",
    "        )\n",
    "        return sensory_location\n",
    "    def __call__(self, visual_input):\n",
    "        \"\"\" The Inference of the visual cortex\n",
    "        The visual cortex carries out a feature extraction process using crtical columns\n",
    "        Args:\n",
    "           visual_input: a tensor of dimentions: height, width, channels (32,32,3)\n",
    "        returns:\n",
    "            visual_features\n",
    "        \"\"\"  \n",
    "        H, W, C = visual_input.shape\n",
    "        assert H == W, \"Must be a square observation\"\n",
    "        assert self.cortical_side_size // H == 0 and self.cortical_side_size < H, 'Cortical Side must perfectly fit'\n",
    "        sensory_location = visual_input\n",
    "        side_size = self.cortical_side_size\n",
    "        n_hidden = self.cortical_n_hidden\n",
    "        hidden_size = self.cortical_hidden_size\n",
    "        output_size = self.cortical_output_size\n",
    "\n",
    "        sensory_location = self.cortical_observation(\n",
    "            sensory_location,\n",
    "            side_size,\n",
    "            n_hidden,\n",
    "            hidden_size,\n",
    "            output_size\n",
    "        )            \n",
    "            \n",
    "        return sensory_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12254707-3f88-4497-b25f-ad39d13b8677",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualCortexConstructor():\n",
    "    def __init__(\n",
    "        self,\n",
    "        seed,\n",
    "        # Inpus dims\n",
    "        input_width_size,\n",
    "        input_height_size,\n",
    "        input_channel_size,\n",
    "        #cortical\n",
    "        cortical_side_size,\n",
    "        cortical_n_hidden,\n",
    "        cortical_hidden_size,\n",
    "        cortical_output_size,\n",
    "        # meta\n",
    "        Logger,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Testing the VisualCortex network\n",
    "        \"\"\"\n",
    "        self.seed = seed\n",
    "        # Input dimensions\n",
    "        self.W = input_width_size\n",
    "        self.H = input_height_size\n",
    "        self.C = input_channel_size\n",
    "\n",
    "        # Cortical Config\n",
    "        self.cortical_side_size = cortical_side_size\n",
    "        self.cortical_n_hidden = cortical_n_hidden\n",
    "        self.cortical_hidden_size = cortical_hidden_size\n",
    "        self.cortical_output_size = cortical_output_size\n",
    "        \n",
    "        # meta\n",
    "        self.NetName = VisualCortex.NetName\n",
    "        self.Logger = Logger\n",
    "\n",
    "    def construct(self):\n",
    "        def net_module(x):\n",
    "            output = VisualCortex(\n",
    "                #\n",
    "                cortical_side_size=self.cortical_side_size,\n",
    "                cortical_n_hidden=self.cortical_n_hidden,\n",
    "                cortical_hidden_size=self.cortical_hidden_size,\n",
    "                cortical_output_size=self.cortical_output_size,\n",
    "            )(x)\n",
    "            return output\n",
    "        key = jax.random.PRNGKey(seed=self.seed)\n",
    "        example_batch = jax.random.normal(key, (self.W, self.H, self.C))\n",
    "        model_init, model_apply = hk.transform(net_module, apply_rng=True)\n",
    "        model_params = model_init(key, example_batch)\n",
    "        return model_init, model_apply, model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0863fa23-ee00-488a-9c4a-9f5578fe6517",
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = { \n",
    "    \"seed\": 0,\n",
    "    \"logger\": 'wandb',\n",
    "    # Reference Frame configuration\n",
    "    # Input configuration\n",
    "    \"input_width_size\": 32,\n",
    "    \"input_height_size\":32,\n",
    "    \"input_channel_size\": 3,\n",
    "    # Cortical Configuration\n",
    "    \"cortical_side_size\": 4,\n",
    "    \"cortical_n_hidden\": 3,\n",
    "    \"cortical_hidden_size\": 8,\n",
    "    \"cortical_output_size\": 16,\n",
    "}\n",
    "logger_config = {\n",
    "    \"name\": 'wandb',\n",
    "    \"api_key\": 'bd0584875dd3c52df37cbd4565c0e22319f9cef6',\n",
    "    \"mode\": 'offline'\n",
    "\n",
    "}\n",
    "logger = WANDBLogger(**logger_config)\n",
    "column_constructor = VisualCortexConstructor(\n",
    "    **configs,\n",
    "    Logger=logger\n",
    ")\n",
    "_, model_apply, model_param = column_constructor.construct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c59dee5-2179-4ca4-9fe3-5c194fba5b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.tree_util.tree_map(lambda x: x.shape, model_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eadf06-ad24-41a2-a580-9f0774ec99af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "def mse(a, b):\n",
    "    return jnp.mean((a - b) ** 2)\n",
    "\n",
    "\n",
    "def mirror_symmetry_loss(img):\n",
    "    \"\"\"\n",
    "    Measures how different an image is from its mirror reflection.\n",
    "    Lower = more symmetric.\n",
    "    \"\"\"\n",
    "    flipped = jnp.flip(img, axis=1)  # horizontal flip\n",
    "    return mse(img, flipped)\n",
    "\n",
    "\n",
    "def rotate_180(img):\n",
    "    \"\"\"Rotate 180° using array reversal.\"\"\"\n",
    "    return jnp.flip(jnp.flip(img, axis=0), axis=1)\n",
    "\n",
    "\n",
    "def rotational_symmetry_loss(img):\n",
    "    \"\"\"\n",
    "    Measures how different an image is from its 180° rotated version.\n",
    "    Lower = more symmetric.\n",
    "    \"\"\"\n",
    "    rotated = rotate_180(img)\n",
    "    return mse(img, rotated)\n",
    "\n",
    "\n",
    "def composite_symmetry_loss(img, w_mirror=0.5, w_rot=0.5):\n",
    "    \"\"\"\n",
    "    Weighted combination of mirror and rotational symmetry.\n",
    "    \"\"\"\n",
    "    m_loss = mirror_symmetry_loss(img)\n",
    "    r_loss = rotational_symmetry_loss(img)\n",
    "    return w_mirror * m_loss + w_rot * r_loss\n",
    "\n",
    "# Example normalization: loss -> score\n",
    "\n",
    "\n",
    "def symmetry_score(img):\n",
    "    loss = composite_symmetry_loss(img)\n",
    "    score = jnp.exp(-5 * loss)  # higher = more symmetric, approx [0,1]\n",
    "    return score\n",
    "\n",
    "\n",
    "def load_image(path):\n",
    "    img = Image.open(path).convert('L').resize((128, 128))\n",
    "    arr = np.array(img) / 255.0\n",
    "    return jnp.array(arr)\n",
    "\n",
    "\n",
    "sym_img = load_image('sym.png')\n",
    "asym_img = load_image('asym.png')\n",
    "\n",
    "sym_score = symmetry_score(sym_img)\n",
    "asym_score = symmetry_score(asym_img)\n",
    "\n",
    "print(\"Symmetric image score:\", float(sym_score))\n",
    "print(\"Asymmetric image score:\", float(asym_score))\n",
    "\n",
    "# Visualization\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axs[0].imshow(sym_img, cmap='gray')\n",
    "axs[0].set_title(f'Symmetric (score={sym_score:.3f})')\n",
    "axs[1].imshow(asym_img, cmap='gray')\n",
    "axs[1].set_title(f'Asymmetric (score={asym_score:.3f})')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9edcfe4-064b-4a2d-91d0-b8759417948c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python aion",
   "language": "python",
   "name": "aion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
